{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Image height: 692\n",
      " Image width: 1038\n",
      " Model version: 2023-02-01-preview\n",
      " Tags:\n",
      "   'text', Confidence 0.9966\n",
      "   'clothing', Confidence 0.9801\n",
      "   'person', Confidence 0.9596\n",
      "   'display device', Confidence 0.9490\n",
      "   'indoor', Confidence 0.9475\n",
      "   'wall', Confidence 0.9396\n",
      "   'media', Confidence 0.9306\n",
      "   'television set', Confidence 0.9281\n",
      "   'led-backlit lcd display', Confidence 0.9255\n",
      "   'flat panel display', Confidence 0.9209\n",
      "   'furniture', Confidence 0.9133\n",
      "   'lcd tv', Confidence 0.8951\n",
      "   'man', Confidence 0.8884\n",
      "   'television', Confidence 0.8766\n",
      "   'video', Confidence 0.8747\n",
      "   'multimedia', Confidence 0.8719\n",
      "   'output device', Confidence 0.8586\n",
      "   'computer monitor', Confidence 0.8442\n",
      "   'table', Confidence 0.8430\n",
      "   'screen', Confidence 0.7113\n",
      "   'standing', Confidence 0.7051\n",
      "   'design', Confidence 0.4042\n",
      " Result details:\n",
      "   Image ID: https://learn.microsoft.com/azure/cognitive-services/computer-vision/media/quickstarts/presentation.png\n",
      "   Result ID: 618ca154-b1b2-4a39-87cc-e3ecced7e533\n",
      "   Connection URL: https://coding-jam-waabey-cv.cognitiveservices.azure.com/computervision/imageanalysis:analyze?api-version=2023-02-01-preview&features=tags&gender-neutral-caption=true&language=en&smartcrops-aspect-ratios=0.9%2C1.33\n",
      "   JSON result: {\"modelVersion\":\"2023-02-01-preview\",\"metadata\":{\"width\":1038,\"height\":692},\"tagsResult\":{\"values\":[{\"name\":\"text\",\"confidence\":0.9966012239456177},{\"name\":\"clothing\",\"confidence\":0.9801060557365417},{\"name\":\"person\",\"confidence\":0.9596296548843384},{\"name\":\"display device\",\"confidence\":0.9490274786949158},{\"name\":\"indoor\",\"confidence\":0.947483241558075},{\"name\":\"wall\",\"confidence\":0.9395941495895386},{\"name\":\"media\",\"confidence\":0.9306115508079529},{\"name\":\"television set\",\"confidence\":0.9280922412872314},{\"name\":\"led-backlit lcd display\",\"confidence\":0.9254804849624634},{\"name\":\"flat panel display\",\"confidence\":0.9209464192390442},{\"name\":\"furniture\",\"confidence\":0.9132548570632935},{\"name\":\"lcd tv\",\"confidence\":0.895058274269104},{\"name\":\"man\",\"confidence\":0.8883916735649109},{\"name\":\"television\",\"confidence\":0.8766454458236694},{\"name\":\"video\",\"confidence\":0.8746980428695679},{\"name\":\"multimedia\",\"confidence\":0.8719364404678345},{\"name\":\"output device\",\"confidence\":0.8585700988769531},{\"name\":\"computer monitor\",\"confidence\":0.844162106513977},{\"name\":\"table\",\"confidence\":0.8429560661315918},{\"name\":\"screen\",\"confidence\":0.7113153338432312},{\"name\":\"standing\",\"confidence\":0.7051211595535278},{\"name\":\"design\",\"confidence\":0.40424615144729614}]}}\n"
     ]
    }
   ],
   "source": [
    "import azure.ai.vision as sdk\n",
    "import os\n",
    "\n",
    "os.environ[\"VISION_KEY\"] = \"5d94265bd61041d083f2ddc67f69eb2f\"\n",
    "os.environ[\"VISION_ENDPOINT\"] = \"https://coding-jam-waabey-cv.cognitiveservices.azure.com/\"\n",
    "\n",
    "# Access the key and endpoint from the environment\n",
    "key = os.environ[\"VISION_KEY\"]\n",
    "endpoint = os.environ[\"VISION_ENDPOINT\"]\n",
    "\n",
    "service_options = sdk.VisionServiceOptions(endpoint, key)\n",
    "\n",
    "vision_source = sdk.VisionSource(\n",
    "    url=\"https://learn.microsoft.com/azure/cognitive-services/computer-vision/media/quickstarts/presentation.png\")\n",
    "\n",
    "analysis_options = sdk.ImageAnalysisOptions()\n",
    "\n",
    "analysis_options.features = sdk.ImageAnalysisFeature.TAGS\n",
    "\n",
    "analysis_options.language = \"en\"\n",
    "\n",
    "analysis_options.gender_neutral_caption = True\n",
    "\n",
    "analysis_options.cropping_aspect_ratios = [0.9, 1.33]\n",
    "\n",
    "image_analyzer = sdk.ImageAnalyzer(service_options, vision_source, analysis_options)\n",
    "\n",
    "result = image_analyzer.analyze()\n",
    "\n",
    "if result.reason == sdk.ImageAnalysisResultReason.ANALYZED:\n",
    "\n",
    "    print(\" Image height: {}\".format(result.image_height))\n",
    "    print(\" Image width: {}\".format(result.image_width))\n",
    "    print(\" Model version: {}\".format(result.model_version))\n",
    "\n",
    "    if result.caption is not None:\n",
    "        print(\" Caption:\")\n",
    "        print(\"   '{}', Confidence {:.4f}\".format(result.caption.content, result.caption.confidence))\n",
    "\n",
    "    if result.dense_captions is not None:\n",
    "        print(\" Dense Captions:\")\n",
    "        for caption in result.dense_captions:\n",
    "            print(\"   '{}', {}, Confidence: {:.4f}\".format(caption.content, caption.bounding_box, caption.confidence))\n",
    "\n",
    "    if result.objects is not None:\n",
    "        print(\" Objects:\")\n",
    "        for object in result.objects:\n",
    "            print(\"   '{}', {}, Confidence: {:.4f}\".format(object.name, object.bounding_box, object.confidence))\n",
    "\n",
    "    if result.tags is not None:\n",
    "        print(\" Tags:\")\n",
    "        for tag in result.tags:\n",
    "            print(\"   '{}', Confidence {:.4f}\".format(tag.name, tag.confidence))\n",
    "\n",
    "    if result.people is not None:\n",
    "        print(\" People:\")\n",
    "        for person in result.people:\n",
    "            print(\"   {}, Confidence {:.4f}\".format(person.bounding_box, person.confidence))\n",
    "\n",
    "    if result.crop_suggestions is not None:\n",
    "        print(\" Crop Suggestions:\")\n",
    "        for crop_suggestion in result.crop_suggestions:\n",
    "            print(\"   Aspect ratio {}: Crop suggestion {}\"\n",
    "                  .format(crop_suggestion.aspect_ratio, crop_suggestion.bounding_box))\n",
    "\n",
    "    if result.text is not None:\n",
    "        print(\" Text:\")\n",
    "        for line in result.text.lines:\n",
    "            points_string = \"{\" + \", \".join([str(int(point)) for point in line.bounding_polygon]) + \"}\"\n",
    "            print(\"   Line: '{}', Bounding polygon {}\".format(line.content, points_string))\n",
    "            for word in line.words:\n",
    "                points_string = \"{\" + \", \".join([str(int(point)) for point in word.bounding_polygon]) + \"}\"\n",
    "                print(\"     Word: '{}', Bounding polygon {}, Confidence {:.4f}\"\n",
    "                      .format(word.content, points_string, word.confidence))\n",
    "\n",
    "    result_details = sdk.ImageAnalysisResultDetails.from_result(result)\n",
    "    print(\" Result details:\")\n",
    "    print(\"   Image ID: {}\".format(result_details.image_id))\n",
    "    print(\"   Result ID: {}\".format(result_details.result_id))\n",
    "    print(\"   Connection URL: {}\".format(result_details.connection_url))\n",
    "    print(\"   JSON result: {}\".format(result_details.json_result))\n",
    "\n",
    "else:\n",
    "\n",
    "    error_details = sdk.ImageAnalysisErrorDetails.from_result(result)\n",
    "    print(\" Analysis failed.\")\n",
    "    print(\"   Error reason: {}\".format(error_details.reason))\n",
    "    print(\"   Error code: {}\".format(error_details.error_code))\n",
    "    print(\"   Error message: {}\".format(error_details.message))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
